{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5ba4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.max_columns\")\n",
    "pd.reset_option(\"display.width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e756930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>exercise</th>\n",
       "      <th>prompt</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>exercise_content</th>\n",
       "      <th>output</th>\n",
       "      <th>token_count</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>cost</th>\n",
       "      <th>thinking_mode</th>\n",
       "      <th>errors</th>\n",
       "      <th>line_with_error</th>\n",
       "      <th>success</th>\n",
       "      <th>run_id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>11_not_closed</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.</td>\n",
       "      <td>Proof.\\nRequire Import Coquelicot.Coquelicot.\\...</td>\n",
       "      <td>6376</td>\n",
       "      <td>280</td>\n",
       "      <td>252</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E11_not_closed_sxc1gooi.v\", line 34...</td>\n",
       "      <td>Require Import Coquelicot.Coquelicot.</td>\n",
       "      <td>False</td>\n",
       "      <td>openai/o4-mini::11_not_closed::1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>11_not_closed</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.</td>\n",
       "      <td>Proof.\\nWe argue by contradiction.\\nAssume tha...</td>\n",
       "      <td>3667</td>\n",
       "      <td>3619</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E11_not_closed_c1ak_nxs.v\", line 35...</td>\n",
       "      <td>Assume that ([0,1) is _closed_).</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::11_not_closed::1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>11_not_closed</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.</td>\n",
       "      <td>Proof.\\n\\nWe need to show that ¬( [0,1) is clo...</td>\n",
       "      <td>368</td>\n",
       "      <td>246</td>\n",
       "      <td>123</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E11_not_closed_2ckg7fcm.v\", line 34...</td>\n",
       "      <td>We need to show that ¬( [0,1) is closed ).</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::11_not_closed::2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>11_not_closed</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.</td>\n",
       "      <td>Proof.\\n\\nWe will prove that the interval [0,1...</td>\n",
       "      <td>493</td>\n",
       "      <td>262</td>\n",
       "      <td>232</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E11_not_closed_9_vfar9d.v\", line 34...</td>\n",
       "      <td>We will prove that the interval [0,1) is not c...</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::11_not_closed::2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>11_not_closed</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.</td>\n",
       "      <td>Proof.\\nWe argue by contradiction.\\nAssume tha...</td>\n",
       "      <td>3684</td>\n",
       "      <td>3619</td>\n",
       "      <td>65</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E11_not_closed_a4j3i0sx.v\", line 35...</td>\n",
       "      <td>Assume that ([0,1) is closed). (i)</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::11_not_closed::2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model       exercise  \\\n",
       "0         openai/o4-mini  11_not_closed   \n",
       "1  x-ai/grok-3-mini-beta  11_not_closed   \n",
       "2  x-ai/grok-3-mini-beta  11_not_closed   \n",
       "3  x-ai/grok-3-mini-beta  11_not_closed   \n",
       "4  x-ai/grok-3-mini-beta  11_not_closed   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  You are asked to write a proof in the syntax o...   \n",
       "1  You are asked to write a proof in the syntax o...   \n",
       "2  You are asked to write a proof in the syntax o...   \n",
       "3  You are asked to write a proof in the syntax o...   \n",
       "4  You are asked to write a proof in the syntax o...   \n",
       "\n",
       "                                            tutorial  \\\n",
       "0  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "1  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "2  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "3  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "4  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "\n",
       "                                    exercise_content  \\\n",
       "0  Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.   \n",
       "1  Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.   \n",
       "2  Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.   \n",
       "3  Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.   \n",
       "4  Lemma not_closed : ¬ ([0,1) is _closed_).\\nProof.   \n",
       "\n",
       "                                              output  token_count  \\\n",
       "0  Proof.\\nRequire Import Coquelicot.Coquelicot.\\...         6376   \n",
       "1  Proof.\\nWe argue by contradiction.\\nAssume tha...         3667   \n",
       "2  Proof.\\n\\nWe need to show that ¬( [0,1) is clo...          368   \n",
       "3  Proof.\\n\\nWe will prove that the interval [0,1...          493   \n",
       "4  Proof.\\nWe argue by contradiction.\\nAssume tha...         3684   \n",
       "\n",
       "   input_tokens  output_tokens      cost  thinking_mode  \\\n",
       "0           280            252  0.027130           True   \n",
       "1          3619             48  0.001110           True   \n",
       "2           246            123  0.000135           True   \n",
       "3           262            232  0.000194           True   \n",
       "4          3619             65  0.001118           True   \n",
       "\n",
       "                                              errors  \\\n",
       "0  File \"/tmp/E11_not_closed_sxc1gooi.v\", line 34...   \n",
       "1  File \"/tmp/E11_not_closed_c1ak_nxs.v\", line 35...   \n",
       "2  File \"/tmp/E11_not_closed_2ckg7fcm.v\", line 34...   \n",
       "3  File \"/tmp/E11_not_closed_9_vfar9d.v\", line 34...   \n",
       "4  File \"/tmp/E11_not_closed_a4j3i0sx.v\", line 35...   \n",
       "\n",
       "                                     line_with_error  success  \\\n",
       "0              Require Import Coquelicot.Coquelicot.    False   \n",
       "1                   Assume that ([0,1) is _closed_).    False   \n",
       "2         We need to show that ¬( [0,1) is closed ).    False   \n",
       "3  We will prove that the interval [0,1) is not c...    False   \n",
       "4                 Assume that ([0,1) is closed). (i)    False   \n",
       "\n",
       "                                    run_id  attempt  max_attempts  \n",
       "0         openai/o4-mini::11_not_closed::1        3             3  \n",
       "1  x-ai/grok-3-mini-beta::11_not_closed::1        1             3  \n",
       "2  x-ai/grok-3-mini-beta::11_not_closed::2        2             3  \n",
       "3  x-ai/grok-3-mini-beta::11_not_closed::2        3             3  \n",
       "4  x-ai/grok-3-mini-beta::11_not_closed::2        1             3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the root directory containing the subdirectories and JSON files\n",
    "root_dir = 'responses'\n",
    "\n",
    "# Prepare a list to collect all the JSON data\n",
    "data_list = []\n",
    "\n",
    "# Walk through the directory tree\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            json_path = os.path.join(subdir, file)\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    data_list.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON: {json_path}\")\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713d220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.10816060000000001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = df['cost'].sum()\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy code to make up pass@k values; delete this later\n",
    "new_success = []\n",
    "\n",
    "for run_id, group in df.groupby('run_id'):\n",
    "    attempts = sorted(group['attempt'].unique())\n",
    "\n",
    "    # Assume max_attempt is the max of current group\n",
    "    max_attempt = max(attempts)\n",
    "    last_attempt = attempts[-1]\n",
    "\n",
    "    a1 = np.random.rand() < 0.3\n",
    "    a2 = a1 or (np.random.rand() < 0.3)\n",
    "    success_map = {\n",
    "        1: a1,\n",
    "        2: a2,\n",
    "        last_attempt: True  # Always succeeds on last attempt\n",
    "    }\n",
    "\n",
    "    # Fill in intermediate attempts if needed\n",
    "    for attempt in attempts:\n",
    "        if attempt not in success_map:\n",
    "            # If more than 3 attempts: fallback logic, extend success from previous\n",
    "            success_map[attempt] = success_map.get(attempt - 1, False)\n",
    "\n",
    "    for attempt in attempts:\n",
    "        new_success.append(success_map[attempt])\n",
    "\n",
    "# Overwrite df['success']\n",
    "df['success'] = new_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c304038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per model}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "model & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "openai/o4-mini & 0.000000 \\\\\n",
      "x-ai/grok-3-mini-beta & 0.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per model\n",
    "summary = df.groupby('model')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per model\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff873336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per exercise}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "exercise & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "11_not_closed & 0.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per exercise (check if this code is correct)\n",
    "summary = df.groupby('exercise')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per exercise\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa34b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>exercise</th>\n",
       "      <th>11_not_closed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>openai/o4-mini</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-ai/grok-3-mini-beta</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "exercise               11_not_closed\n",
       "model                               \n",
       "openai/o4-mini                   0.0\n",
       "x-ai/grok-3-mini-beta            0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid of success rates per model and per exercise (requires multiple runs of all models)\n",
    "grid = df.pivot_table(index='model', columns='exercise', values='success', aggfunc='mean') * 100\n",
    "grid = grid.round(2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3385308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Output Tokens</th>\n",
       "      <th>thinking_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>305.666667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>168.666667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Avg Output Tokens  thinking_mode\n",
       "0         openai/o4-mini         305.666667           True\n",
       "1  x-ai/grok-3-mini-beta         168.666667           True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average output token counts per model\n",
    "output_tokens_avg = df.groupby('model')['output_tokens'].mean().reset_index()\n",
    "output_tokens_avg.rename(columns={'output_tokens': 'Avg Output Tokens'}, inplace=True)\n",
    "\n",
    "# Get the thinking_mode per model\n",
    "thinking_mode_per_model = df[['model', 'thinking_mode']].drop_duplicates()\n",
    "\n",
    "# Merge into the result\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_mode_per_model, on='model')\n",
    "\n",
    "output_tokens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9305b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Cost ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.017530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Avg Cost ($)\n",
       "0         openai/o4-mini      0.017530\n",
       "1  x-ai/grok-3-mini-beta      0.000497"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cost per model\n",
    "cost_avg = df.groupby('model')['cost'].mean().reset_index()\n",
    "cost_avg.rename(columns={'cost': 'Avg Cost ($)'}, inplace=True)\n",
    "cost_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d371e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Tutorial Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Tutorial Length  Success Rate (%)\n",
       "0         openai/o4-mini             8665               0.0\n",
       "1  x-ai/grok-3-mini-beta             8665               0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of tutorial verbosity\n",
    "df['tutorial_len'] = df['tutorial'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "tutorial_success = df.groupby(['model', 'tutorial_len'])['success'].mean().reset_index()\n",
    "tutorial_success['success'] = (tutorial_success['success'] * 100).round(2)\n",
    "tutorial_success.rename(columns={'success': 'Success Rate (%)', 'tutorial_len': 'Tutorial Length'}, inplace=True)\n",
    "\n",
    "tutorial_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15669877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Prompt Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Prompt Length  Success Rate (%)\n",
       "0         openai/o4-mini           1294               0.0\n",
       "1  x-ai/grok-3-mini-beta           1294               0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of prompt verbosity\n",
    "df['prompt_len'] = df['prompt'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "prompt_success = df.groupby(['model', 'prompt_len'])['success'].mean().reset_index()\n",
    "prompt_success['success'] = (prompt_success['success'] * 100).round(2)\n",
    "prompt_success.rename(columns={'success': 'Success Rate (%)', 'prompt_len': 'Prompt Length'}, inplace=True)\n",
    "\n",
    "prompt_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3f29623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [errors]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['exercise'] == '6_8_1']\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_filtered['errors'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00323cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_with_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [line_with_error]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['line_with_error'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72e35710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Pass@1 (%)</th>\n",
       "      <th>Pass@2 (%)</th>\n",
       "      <th>Pass@3 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Pass@1 (%)  Pass@2 (%)  Pass@3 (%)\n",
       "0         openai/o4-mini         0.0       100.0       100.0\n",
       "1  x-ai/grok-3-mini-beta        50.0        50.0       100.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by run_id to get per-run summary\n",
    "run_grouped = df.groupby('run_id').agg({\n",
    "    'model': 'first',\n",
    "    'success': list,\n",
    "    'attempt': 'max',\n",
    "    'max_attempts': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Expand success list into per-k success map\n",
    "max_k = df['max_attempts'].max()\n",
    "\n",
    "for k in range(1, max_k + 1):\n",
    "    def pass_at_k(row):\n",
    "        successes = row['success']\n",
    "        used_attempts = row['attempt']\n",
    "        # Success in any of the first k attempts\n",
    "        success_in_k = any(successes[:k])\n",
    "        # Or the model didn't even use k attempts\n",
    "        not_used_k = used_attempts < k\n",
    "        return success_in_k or not_used_k\n",
    "\n",
    "    run_grouped[f'pass@{k}'] = run_grouped.apply(pass_at_k, axis=1)\n",
    "\n",
    "# Now compute per-model mean for each pass@k\n",
    "passk_cols = [f'pass@{k}' for k in range(1, max_k + 1)]\n",
    "passk_summary = run_grouped.groupby('model')[passk_cols].mean().reset_index()\n",
    "\n",
    "# Convert to percentage\n",
    "for col in passk_cols:\n",
    "    passk_summary[col] = (passk_summary[col] * 100).round(2)\n",
    "\n",
    "# Rename columns for display\n",
    "passk_summary.rename(columns={col: f'Pass@{col[-1]} (%)' for col in passk_cols}, inplace=True)\n",
    "\n",
    "passk_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# thinking vs no thinking models (all)\n",
    "# thinking vs no thinking on models that support both (fair)\n",
    "# definition expanding comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
