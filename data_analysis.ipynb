{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ba4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jinja2\n",
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.max_columns\")\n",
    "pd.reset_option(\"display.width\")\n",
    "pd.set_option('display.max_colwidth', 100)  # default is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e756930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of root directories to process\n",
    "\n",
    "#this is for cost eval\n",
    "#root_dirs = [\n",
    "#    \"experiments/1_cost_assessment_per_model_no_defs/results/2025-06-08_20-28-18\",\n",
    "#    \"experiments/1_cost_assessment_per_model_no_defs/results/2025-06-08_21-04-01\",\n",
    "#    \"experiments/1_cost_assessment_per_model/results/2025-06-08_20-13-16\",\n",
    "#    \"experiments/1_cost_assessment_per_model/results/2025-06-08_20-58-45\"\n",
    "#]\n",
    "\n",
    "root_dirs = [\n",
    "    \"experiments/5_tvn_less_models_defs_context\",\n",
    "    \"experiments/4_tvn_defs_no_context\"\n",
    "]\n",
    "\n",
    "# Prepare a list to collect all the JSON data\n",
    "data_list = []\n",
    "\n",
    "# Walk through each directory\n",
    "for root_dir in root_dirs:\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_path = os.path.join(subdir, file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        data_list.append(data)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Failed to decode JSON: {json_path}\")\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Define models to exclude\n",
    "exclude_models = ['openai/o4-mini-high', 'openai/gpt-4o-mini']\n",
    "\n",
    "# Drop rows where model is in exclude_models\n",
    "df = df[~df['model'].isin(exclude_models)]\n",
    "\n",
    "# Example: check number of rows\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf5c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempt</th>\n",
       "      <th>error_message</th>\n",
       "      <th>line_with_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>Error: Wrong assumption specified.\\n\\n</td>\n",
       "      <td>Assume that (∀ a, [0, 1) a ⇨ ∃ r &gt; 0, ∀ x ∈ B(a, r), x ∈ [0, 1)).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>Error: Wrong assumption specified.\\n\\n</td>\n",
       "      <td>Assume that ([0,1) is _open_).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>Error: Syntax error: ',' or 'in' '(' expected (in [ltac2_expr]).\\n\\n</td>\n",
       "      <td>Use a := (0) in this statement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>Error: You cannot do this right now, follow the advice in the goal window.\\n\\n</td>\n",
       "      <td>* Indeed, ([0, 1) 0).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>Error: Could not verify that ((B(0, r)) (- r / 2)).\\n\\n</td>\n",
       "      <td>It holds that (B(0, r) (-r/2)).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>Error: Syntax error: [term level 200] expected after '(' (in [term]).\\n\\n</td>\n",
       "      <td>It holds that (|-r/2 - 0| &lt; r).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    attempt  \\\n",
       "52        1   \n",
       "41        2   \n",
       "54        3   \n",
       "61        4   \n",
       "60        5   \n",
       "28        6   \n",
       "40        7   \n",
       "\n",
       "                                                                     error_message  \\\n",
       "52                                          Error: Wrong assumption specified.\\n\\n   \n",
       "41                                          Error: Wrong assumption specified.\\n\\n   \n",
       "54            Error: Syntax error: ',' or 'in' '(' expected (in [ltac2_expr]).\\n\\n   \n",
       "61  Error: You cannot do this right now, follow the advice in the goal window.\\n\\n   \n",
       "60                         Error: Could not verify that ((B(0, r)) (- r / 2)).\\n\\n   \n",
       "28       Error: Syntax error: [term level 200] expected after '(' (in [term]).\\n\\n   \n",
       "40                                                                                   \n",
       "\n",
       "                                                      line_with_error  \n",
       "52  Assume that (∀ a, [0, 1) a ⇨ ∃ r > 0, ∀ x ∈ B(a, r), x ∈ [0, 1)).  \n",
       "41                                     Assume that ([0,1) is _open_).  \n",
       "54                                    Use a := (0) in this statement.  \n",
       "61                                              * Indeed, ([0, 1) 0).  \n",
       "60                                    It holds that (B(0, r) (-r/2)).  \n",
       "28                                    It holds that (|-r/2 - 0| < r).  \n",
       "40                                                               None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model you want to inspect\n",
    "model_to_inspect = 'anthropic/claude-sonnet-4'  # replace with your model\n",
    "\n",
    "df_model = df[df['model'] == model_to_inspect].sort_values(by=['run_id', 'attempt']).copy()\n",
    "\n",
    "df_model['error_message'] = df_model['errors'].apply(\n",
    "    lambda x: x.split('\\n', 1)[1] if isinstance(x, str) and '\\n' in x else ''\n",
    ")\n",
    "\n",
    "#df_model.head()\n",
    "df_model[['attempt', 'error_message', 'line_with_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771351b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof.\n",
      "We need to show that (¬ ([0,1) is _open_)).\n",
      "We argue by contradiction.\n",
      "Assume that (¬ (¬ ([0,1) is _open_))).\n",
      "It holds that ([0,1) is _open_).\n",
      "It holds that (∀ a, [0, 1) a ⇨ a is an _interior point_ of [0, 1)) (i).\n",
      "By (i) it holds that ([0, 1) 0 ⇨ 0 is an _interior point_ of [0, 1)).\n",
      "It holds that ([0, 1) 0).\n",
      "It holds that (0 is an _interior point_ of [0, 1)).\n",
      "It holds that (∃ r > 0, ∀ x ∈ B(0, r), x ∈ [0, 1)).\n",
      "Obtain such an r.\n",
      "It holds that (∀ x ∈ B(0, r), x ∈ [0, 1)) (ii).\n",
      "By (ii) it holds that (B(0, r) (-r/2) ⇨ (-r/2) ∈ [0, 1)).\n",
      "It holds that (B(0, r) (-r/2)).\n",
      "It holds that ((-r/2) ∈ [0, 1)).\n",
      "It holds that (-r/2 ≥ 0).\n",
      "It holds that (-r/2 < 0).\n",
      "Contradiction.\n",
      "Qed.\n"
     ]
    }
   ],
   "source": [
    "attempt_number = 5\n",
    "\n",
    "df_proof = df_model[df_model['attempt'] == attempt_number].copy()\n",
    "proof = df_proof['output'].iloc[0]\n",
    "\n",
    "print(proof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "713d220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.8525817499999997)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = df['cost'].sum()\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total success rate per model\n",
    "summary = df.groupby('model')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per model\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff873336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total success rate per exercise (check if this code is correct)\n",
    "summary = df.groupby('exercise')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per exercise\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baa34b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>exercise</th>\n",
       "      <th>11_not_open</th>\n",
       "      <th>3_11_2</th>\n",
       "      <th>4_9_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-sonnet-4</th>\n",
       "      <td>5.88</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20</th>\n",
       "      <td>0.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20:thinking</th>\n",
       "      <td>0.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/gpt-4.1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o3-mini</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o4-mini</th>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-ai/grok-3-beta</th>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-ai/grok-3-mini-beta</th>\n",
       "      <td>0.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "exercise                                        11_not_open  3_11_2  4_9_1\n",
       "model                                                                     \n",
       "anthropic/claude-sonnet-4                              5.88   100.0  50.00\n",
       "google/gemini-2.5-flash-preview-05-20                  0.00    50.0   0.00\n",
       "google/gemini-2.5-flash-preview-05-20:thinking         0.00    50.0  66.67\n",
       "openai/gpt-4.1                                         0.00    25.0   0.00\n",
       "openai/o3-mini                                         0.00     0.0   0.00\n",
       "openai/o4-mini                                         0.00   100.0  10.00\n",
       "x-ai/grok-3-beta                                       0.00     NaN    NaN\n",
       "x-ai/grok-3-mini-beta                                  0.00   100.0   8.33"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid of success rates per model and per exercise (requires multiple runs of all models)\n",
    "grid = df.pivot_table(index='model', columns='exercise', values='success', aggfunc='mean') * 100\n",
    "grid = grid.round(2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3385308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Output Tokens</th>\n",
       "      <th>thinking_mode</th>\n",
       "      <th>Avg Thinking Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>370.857143</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>424.800000</td>\n",
       "      <td>True</td>\n",
       "      <td>6018.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>273.700000</td>\n",
       "      <td>True</td>\n",
       "      <td>6786.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x-ai/grok-3-beta</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>246.600000</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  Avg Output Tokens  thinking_mode  Avg Thinking Tokens\n",
       "0                       anthropic/claude-sonnet-4         370.857143          False                  0.0\n",
       "1  google/gemini-2.5-flash-preview-05-20:thinking         424.800000           True               6018.9\n",
       "2                                  openai/o4-mini         273.700000           True               6786.6\n",
       "3                                x-ai/grok-3-beta         262.000000          False                  0.0\n",
       "4                           x-ai/grok-3-mini-beta         246.600000           True                 -0.3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average output token counts per model\n",
    "output_tokens_avg = df.groupby('model')['output_tokens'].mean().reset_index()\n",
    "output_tokens_avg.rename(columns={'output_tokens': 'Avg Output Tokens'}, inplace=True)\n",
    "\n",
    "# Average thinking token counts per model\n",
    "thinking_tokens_avg = df.groupby('model')['thinking_tokens'].mean().reset_index()\n",
    "thinking_tokens_avg.rename(columns={'thinking_tokens': 'Avg Thinking Tokens'}, inplace=True)\n",
    "\n",
    "# Get the thinking_mode per model\n",
    "thinking_mode_per_model = df[['model', 'thinking_mode']].drop_duplicates()\n",
    "\n",
    "# Merge into the result\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_mode_per_model, on='model')\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_tokens_avg, on='model')\n",
    "\n",
    "output_tokens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9305b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Cost ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>0.004954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>0.016139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.026379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x-ai/grok-3-beta</td>\n",
       "      <td>0.028501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>0.029369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  Avg Cost ($)\n",
       "7                           x-ai/grok-3-mini-beta      0.002066\n",
       "3                                  openai/gpt-4.1      0.003471\n",
       "1           google/gemini-2.5-flash-preview-05-20      0.003739\n",
       "2  google/gemini-2.5-flash-preview-05-20:thinking      0.004954\n",
       "4                                  openai/o3-mini      0.016139\n",
       "5                                  openai/o4-mini      0.026379\n",
       "6                                x-ai/grok-3-beta      0.028501\n",
       "0                       anthropic/claude-sonnet-4      0.029369"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cost per model\n",
    "cost_avg = df.groupby('model')['cost'].mean().reset_index()\n",
    "cost_avg.rename(columns={'cost': 'Avg Cost ($)'}, inplace=True)\n",
    "cost_avg.sort_values(\"Avg Cost ($)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c4eb60e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Model Pair</th>\n",
       "      <th>Cost Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic</td>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking vs anthropic/claude-sonnet-4</td>\n",
       "      <td>6.525463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek</td>\n",
       "      <td>deepseek/deepseek-r1-0528 vs deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>2.290332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google</td>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking vs google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>1.325095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openai</td>\n",
       "      <td>openai/o4-mini vs openai/gpt-4.1</td>\n",
       "      <td>7.498808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company  \\\n",
       "0  anthropic   \n",
       "1   deepseek   \n",
       "2     google   \n",
       "3     openai   \n",
       "\n",
       "                                                                                Model Pair  \\\n",
       "0                        anthropic/claude-3.7-sonnet:thinking vs anthropic/claude-sonnet-4   \n",
       "1                              deepseek/deepseek-r1-0528 vs deepseek/deepseek-chat-v3-0324   \n",
       "2  google/gemini-2.5-flash-preview-05-20:thinking vs google/gemini-2.5-flash-preview-05-20   \n",
       "3                                                         openai/o4-mini vs openai/gpt-4.1   \n",
       "\n",
       "   Cost Ratio  \n",
       "0    6.525463  \n",
       "1    2.290332  \n",
       "2    1.325095  \n",
       "3    7.498808  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract company from model name\n",
    "cost_avg['company'] = cost_avg['model'].str.split('/').str[0]\n",
    "\n",
    "# Compute ratio per company\n",
    "ratios = []\n",
    "\n",
    "for company, group in cost_avg.groupby('company'):\n",
    "    group_sorted = group.sort_values('Avg Cost ($)')\n",
    "    \n",
    "    if len(group_sorted) >= 2:\n",
    "        cheaper = group_sorted.iloc[0]\n",
    "        more_expensive = group_sorted.iloc[-1]\n",
    "        \n",
    "        ratio = more_expensive['Avg Cost ($)'] / cheaper['Avg Cost ($)']\n",
    "        model_pair = f\"{more_expensive['model']} vs {cheaper['model']}\"\n",
    "        \n",
    "        ratios.append({'Company': company, 'Model Pair': model_pair, 'Cost Ratio': ratio})\n",
    "    else:\n",
    "        # Optionally, you can skip or report companies with only 1 model\n",
    "        pass\n",
    "\n",
    "# Convert to DataFrame\n",
    "ratios_df = pd.DataFrame(ratios)\n",
    "ratios_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4af874d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>attempt</th>\n",
       "      <th>Avg Cost ($)</th>\n",
       "      <th>thinking_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek/deepseek-r1-0528</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deepseek/deepseek-r1-0528</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  attempt  Avg Cost ($)  \\\n",
       "2                        anthropic/claude-sonnet-4        1      0.023674   \n",
       "3                        anthropic/claude-sonnet-4        2      0.025472   \n",
       "4                   deepseek/deepseek-chat-v3-0324        1      0.001475   \n",
       "5                   deepseek/deepseek-chat-v3-0324        2      0.001724   \n",
       "8            google/gemini-2.5-flash-preview-05-20        1      0.001005   \n",
       "9            google/gemini-2.5-flash-preview-05-20        2      0.001116   \n",
       "12                                  openai/gpt-4.1        1      0.000862   \n",
       "13                                  openai/gpt-4.1        2      0.000985   \n",
       "0             anthropic/claude-3.7-sonnet:thinking        1      0.209818   \n",
       "1             anthropic/claude-3.7-sonnet:thinking        2      0.093280   \n",
       "6                        deepseek/deepseek-r1-0528        1      0.011071   \n",
       "7                        deepseek/deepseek-r1-0528        2      0.015358   \n",
       "10  google/gemini-2.5-flash-preview-05-20:thinking        1      0.004830   \n",
       "11  google/gemini-2.5-flash-preview-05-20:thinking        2      0.004046   \n",
       "14                                  openai/o4-mini        1      0.027080   \n",
       "15                                  openai/o4-mini        2      0.025276   \n",
       "\n",
       "    thinking_mode  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "5             0.0  \n",
       "8             0.0  \n",
       "9             0.0  \n",
       "12            0.0  \n",
       "13            0.0  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "6             1.0  \n",
       "7             1.0  \n",
       "10            1.0  \n",
       "11            1.0  \n",
       "14            1.0  \n",
       "15            1.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cost per model per attempt\n",
    "cost_avg_attempt = df.groupby(['model', 'attempt'])[['cost', 'thinking_mode']].mean().reset_index()\n",
    "cost_avg_attempt.rename(columns={'cost': 'Avg Cost ($)'}, inplace=True)\n",
    "cost_avg_attempt.sort_values(['thinking_mode', 'model', 'attempt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4c838ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success?</th>\n",
       "      <th>Attempts Used</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-sonnet-4</th>\n",
       "      <td>1/1</td>\n",
       "      <td>10/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-3.7-sonnet:thinking</th>\n",
       "      <td>0/1</td>\n",
       "      <td>3/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-chat-v3-0324</th>\n",
       "      <td>0/1</td>\n",
       "      <td>32/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1-0528</th>\n",
       "      <td>0/1</td>\n",
       "      <td>10/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20</th>\n",
       "      <td>0/1</td>\n",
       "      <td>50/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20:thinking</th>\n",
       "      <td>0/1</td>\n",
       "      <td>15/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/gpt-4.1</th>\n",
       "      <td>0/1</td>\n",
       "      <td>50/50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o4-mini</th>\n",
       "      <td>0/1</td>\n",
       "      <td>5/50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Success? Attempts Used\n",
       "model                                                                \n",
       "anthropic/claude-sonnet-4                           1/1         10/50\n",
       "anthropic/claude-3.7-sonnet:thinking                0/1          3/50\n",
       "deepseek/deepseek-chat-v3-0324                      0/1         32/50\n",
       "deepseek/deepseek-r1-0528                           0/1         10/50\n",
       "google/gemini-2.5-flash-preview-05-20               0/1         50/50\n",
       "google/gemini-2.5-flash-preview-05-20:thinking      0/1         15/50\n",
       "openai/gpt-4.1                                      0/1         50/50\n",
       "openai/o4-mini                                      0/1          5/50"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to exercise 3_11_4\n",
    "df_3114 = df[df['exercise'] == '3_11_4']\n",
    "\n",
    "# Total runs per model = number of unique run_ids per model\n",
    "total_runs = df_3114.groupby('model')['run_id'].nunique()\n",
    "\n",
    "# Successful runs per model:\n",
    "# For each run_id, if any row was success == True → that run counts as successful\n",
    "success_per_run = df_3114.groupby(['model', 'run_id'])['success'].max().reset_index()\n",
    "\n",
    "# Now count number of successful runs per model\n",
    "successful_runs = success_per_run.groupby('model')['success'].sum()\n",
    "\n",
    "# Attempts used per run_id:\n",
    "# For each run_id, the max(attempt) in that run tells how many attempts were used\n",
    "attempts_per_run = df_3114.groupby(['model', 'run_id'])['attempt'].max().reset_index()\n",
    "\n",
    "# Now sum attempts used per model\n",
    "total_attempts_used = attempts_per_run.groupby('model')['attempt'].sum()\n",
    "\n",
    "# Max possible attempts = total_runs * max_attempts_per_run\n",
    "# We can infer max_attempts_per_run from the data:\n",
    "max_attempts_per_run = df_3114['attempt'].max()\n",
    "total_possible_attempts = total_runs * max_attempts_per_run\n",
    "\n",
    "# Combine into one DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Success?': successful_runs,\n",
    "    'Total Runs': total_runs,\n",
    "    'Attempts Used': total_attempts_used,\n",
    "    'Possible Attempts': total_possible_attempts\n",
    "})\n",
    "\n",
    "# Format columns\n",
    "summary_df['Success?'] = summary_df['Success?'].astype(int).astype(str) + '/' + summary_df['Total Runs'].astype(int).astype(str)\n",
    "summary_df['Attempts Used'] = summary_df['Attempts Used'].astype(int).astype(str) + '/' + summary_df['Possible Attempts'].astype(int).astype(str)\n",
    "\n",
    "# Final columns\n",
    "summary_df = summary_df[['Success?', 'Attempts Used']]\n",
    "\n",
    "# Optional: sort by success rate descending\n",
    "summary_df = summary_df.sort_values(by='Success?', ascending=False)\n",
    "\n",
    "# Display\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d371e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Tutorial Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-r1-0528</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  Tutorial Length  \\\n",
       "0            anthropic/claude-3.7-sonnet:thinking             8665   \n",
       "1                       anthropic/claude-sonnet-4             8665   \n",
       "2                  deepseek/deepseek-chat-v3-0324             8665   \n",
       "3                       deepseek/deepseek-r1-0528             8665   \n",
       "4           google/gemini-2.5-flash-preview-05-20             8665   \n",
       "5  google/gemini-2.5-flash-preview-05-20:thinking             8665   \n",
       "6                                  openai/gpt-4.1             8665   \n",
       "7                                  openai/o4-mini             8665   \n",
       "\n",
       "   Success Rate (%)  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               0.0  \n",
       "6               0.0  \n",
       "7               0.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of tutorial verbosity\n",
    "df['tutorial_len'] = df['tutorial'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "tutorial_success = df.groupby(['model', 'tutorial_len'])['success'].mean().reset_index()\n",
    "tutorial_success['success'] = (tutorial_success['success'] * 100).round(2)\n",
    "tutorial_success.rename(columns={'success': 'Success Rate (%)', 'tutorial_len': 'Tutorial Length'}, inplace=True)\n",
    "\n",
    "tutorial_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15669877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Prompt Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>1294</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Prompt Length  Success Rate (%)\n",
       "0         openai/o4-mini           1294             18.18\n",
       "1  x-ai/grok-3-mini-beta           1294             16.67"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of prompt verbosity\n",
    "df['prompt_len'] = df['prompt'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "prompt_success = df.groupby(['model', 'prompt_len'])['success'].mean().reset_index()\n",
    "prompt_success['success'] = (prompt_success['success'] * 100).round(2)\n",
    "prompt_success.rename(columns={'success': 'Success Rate (%)', 'prompt_len': 'Prompt Length'}, inplace=True)\n",
    "\n",
    "prompt_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3f29623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [errors]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['exercise'] == '6_8_1']\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_filtered['errors'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00323cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_with_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [line_with_error]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['line_with_error'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72e35710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Pass@1 (%)</th>\n",
       "      <th>Pass@2 (%)</th>\n",
       "      <th>Pass@3 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Pass@1 (%)  Pass@2 (%)  Pass@3 (%)\n",
       "0         openai/o4-mini        25.0        50.0        50.0\n",
       "1  x-ai/grok-3-mini-beta        50.0        50.0        50.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by run_id to get per-run summary\n",
    "run_grouped = df.groupby('run_id').agg({\n",
    "    'model': 'first',\n",
    "    'success': list,\n",
    "    'attempt': 'max',\n",
    "    'max_attempts': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Expand success list into per-k success map\n",
    "max_k = df['max_attempts'].max()\n",
    "\n",
    "for k in range(1, max_k + 1):\n",
    "    def pass_at_k(row):\n",
    "        successes = row['success']\n",
    "        used_attempts = row['attempt']\n",
    "        # Success in any of the first k attempts\n",
    "        success_in_k = any(successes[:k])\n",
    "        # Or the model didn't even use k attempts\n",
    "        not_used_k = used_attempts < k\n",
    "        return success_in_k or not_used_k\n",
    "\n",
    "    run_grouped[f'pass@{k}'] = run_grouped.apply(pass_at_k, axis=1)\n",
    "\n",
    "# Now compute per-model mean for each pass@k\n",
    "passk_cols = [f'pass@{k}' for k in range(1, max_k + 1)]\n",
    "passk_summary = run_grouped.groupby('model')[passk_cols].mean().reset_index()\n",
    "\n",
    "# Convert to percentage\n",
    "for col in passk_cols:\n",
    "    passk_summary[col] = (passk_summary[col] * 100).round(2)\n",
    "\n",
    "# Rename columns for display\n",
    "passk_summary.rename(columns={col: f'Pass@{col[-1]} (%)' for col in passk_cols}, inplace=True)\n",
    "\n",
    "passk_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# thinking vs no thinking models (all)\n",
    "# thinking vs no thinking on models that support both (fair)\n",
    "# definition expanding comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
