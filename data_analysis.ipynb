{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jinja2\n",
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.max_columns\")\n",
    "pd.reset_option(\"display.width\")\n",
    "pd.set_option('display.max_colwidth', 100)  # default is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e756930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>exercise</th>\n",
       "      <th>prompt</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>full_input</th>\n",
       "      <th>exercise_content</th>\n",
       "      <th>output</th>\n",
       "      <th>token_count</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>cost</th>\n",
       "      <th>thinking_mode</th>\n",
       "      <th>errors</th>\n",
       "      <th>line_with_error</th>\n",
       "      <th>success</th>\n",
       "      <th>run_id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>6339</td>\n",
       "      <td>3789</td>\n",
       "      <td>152</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E3_11_2_940yw9tg.v\", line 42, characters 0-59:\\nError: Expected a single focused goal...</td>\n",
       "      <td>We need to show that (∀ u &gt; 0, ∃ v &gt; 0, x + u &lt; y + v).</td>\n",
       "      <td>False</td>\n",
       "      <td>openai/o4-mini::3_11_2::1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Proof.\\nTake x ∈ ℝ.\\nWe need to show that (∃ y ∈ ℝ, ∀ u &gt; 0, ∃ v &gt; 0, x + u &lt; y + v).\\nChoose y ...</td>\n",
       "      <td>5245</td>\n",
       "      <td>4180</td>\n",
       "      <td>142</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E3_11_2_w227ubbz.v\", line 43, characters 0-59:\\nError: Expected a single focused goal...</td>\n",
       "      <td>We need to show that (∀ u &gt; 0, ∃ v &gt; 0, x + u &lt; y + v).</td>\n",
       "      <td>False</td>\n",
       "      <td>openai/o4-mini::3_11_2::2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n* Indeed, (y ∈ ℝ).\\nTake u &gt; 0.\\nChoose v := u.\\n- In...</td>\n",
       "      <td>3713</td>\n",
       "      <td>3651</td>\n",
       "      <td>59</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E3_11_2_alo6szn8.v\", line 42, characters 0-11:\\nError: Expected a single focused goal...</td>\n",
       "      <td>Take u &gt; 0.</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::3_11_2::1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Proof.\\nTake x ∈ ℝ.\\nWe need to show that (∃ y ∈ ℝ, ∀ u &gt; 0, ∃ v &gt; 0, x + u &lt; y + v).\\nChoose y ...</td>\n",
       "      <td>3775</td>\n",
       "      <td>3651</td>\n",
       "      <td>118</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E3_11_2_cx9i8fg1.v\", line 43, characters 0-59:\\nError: Expected a single focused goal...</td>\n",
       "      <td>We need to show that (∀ u &gt; 0, ∃ v &gt; 0, x + u &lt; y + v).</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::3_11_2::2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n- Indeed, (y ∈ ℝ).\\nTake u &gt; 0.\\nChoose v := u.\\n* In...</td>\n",
       "      <td>4108</td>\n",
       "      <td>4046</td>\n",
       "      <td>59</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E3_11_2_ooso6g6b.v\", line 42, characters 0-11:\\nError: Expected a single focused goal...</td>\n",
       "      <td>Take u &gt; 0.</td>\n",
       "      <td>False</td>\n",
       "      <td>x-ai/grok-3-mini-beta::3_11_2::2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>3_11_2</td>\n",
       "      <td>You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...</td>\n",
       "      <td>Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...</td>\n",
       "      <td>Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u &gt; 0,\\n          ∃ v &gt; 0, x + u &lt; y ...</td>\n",
       "      <td>Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n* Indeed, (y ∈ ℝ).\\n* We need to show that (∀ u &gt; 0, ...</td>\n",
       "      <td>4451</td>\n",
       "      <td>4356</td>\n",
       "      <td>91</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>x-ai/grok-3-mini-beta::3_11_2::2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model exercise  \\\n",
       "2         openai/o4-mini   3_11_2   \n",
       "5         openai/o4-mini   3_11_2   \n",
       "4  x-ai/grok-3-mini-beta   3_11_2   \n",
       "3  x-ai/grok-3-mini-beta   3_11_2   \n",
       "1  x-ai/grok-3-mini-beta   3_11_2   \n",
       "0  x-ai/grok-3-mini-beta   3_11_2   \n",
       "\n",
       "                                                                                                prompt  \\\n",
       "2  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "5  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "4  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "3  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "1  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "0  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "\n",
       "                                                                                              tutorial  \\\n",
       "2  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "5  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "4  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "3  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "1  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "0  # Waterproof Tutorial\\n\\n## 1. We conclude that\\n\\n### Example:\\n\\nLemma example_reflexivity :\\n...   \n",
       "\n",
       "                                                                                            full_input  \\\n",
       "2  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "5  Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...   \n",
       "4  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "3  You are asked to write a proof in the syntax of Waterproof, a theorem proving educational softwa...   \n",
       "1  Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...   \n",
       "0  Your proof seems to have some mistakes in it, as it does not compile correctly.\\nHere is the err...   \n",
       "\n",
       "                                                                                      exercise_content  \\\n",
       "2  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "5  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "4  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "3  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "1  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "0  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "\n",
       "                                                                                                output  \\\n",
       "2  Lemma exercise_3_11_2 :\\n  ∀ x ∈ ℝ,\\n    ∃ y ∈ ℝ,\\n      ∀ u > 0,\\n          ∃ v > 0, x + u < y ...   \n",
       "5  Proof.\\nTake x ∈ ℝ.\\nWe need to show that (∃ y ∈ ℝ, ∀ u > 0, ∃ v > 0, x + u < y + v).\\nChoose y ...   \n",
       "4  Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n* Indeed, (y ∈ ℝ).\\nTake u > 0.\\nChoose v := u.\\n- In...   \n",
       "3  Proof.\\nTake x ∈ ℝ.\\nWe need to show that (∃ y ∈ ℝ, ∀ u > 0, ∃ v > 0, x + u < y + v).\\nChoose y ...   \n",
       "1  Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n- Indeed, (y ∈ ℝ).\\nTake u > 0.\\nChoose v := u.\\n* In...   \n",
       "0  Proof.\\nTake x ∈ ℝ.\\nChoose y := (x + 1).\\n* Indeed, (y ∈ ℝ).\\n* We need to show that (∀ u > 0, ...   \n",
       "\n",
       "   token_count  input_tokens  output_tokens      cost  thinking_mode  \\\n",
       "2         6339          3789            152  0.015388           True   \n",
       "5         5245          4180            142  0.009284           True   \n",
       "4         3713          3651             59  0.001126           True   \n",
       "3         3775          3651            118  0.001157           True   \n",
       "1         4108          4046             59  0.001245           True   \n",
       "0         4451          4356             91  0.001354           True   \n",
       "\n",
       "                                                                                                errors  \\\n",
       "2  File \"/tmp/E3_11_2_940yw9tg.v\", line 42, characters 0-59:\\nError: Expected a single focused goal...   \n",
       "5  File \"/tmp/E3_11_2_w227ubbz.v\", line 43, characters 0-59:\\nError: Expected a single focused goal...   \n",
       "4  File \"/tmp/E3_11_2_alo6szn8.v\", line 42, characters 0-11:\\nError: Expected a single focused goal...   \n",
       "3  File \"/tmp/E3_11_2_cx9i8fg1.v\", line 43, characters 0-59:\\nError: Expected a single focused goal...   \n",
       "1  File \"/tmp/E3_11_2_ooso6g6b.v\", line 42, characters 0-11:\\nError: Expected a single focused goal...   \n",
       "0                                                                                                        \n",
       "\n",
       "                                           line_with_error  success  \\\n",
       "2  We need to show that (∀ u > 0, ∃ v > 0, x + u < y + v).    False   \n",
       "5  We need to show that (∀ u > 0, ∃ v > 0, x + u < y + v).    False   \n",
       "4                                              Take u > 0.    False   \n",
       "3  We need to show that (∀ u > 0, ∃ v > 0, x + u < y + v).    False   \n",
       "1                                              Take u > 0.    False   \n",
       "0                                                     None     True   \n",
       "\n",
       "                             run_id  attempt  max_attempts  \n",
       "2         openai/o4-mini::3_11_2::1        1             3  \n",
       "5         openai/o4-mini::3_11_2::2        2             3  \n",
       "4  x-ai/grok-3-mini-beta::3_11_2::1        1             3  \n",
       "3  x-ai/grok-3-mini-beta::3_11_2::2        1             3  \n",
       "1  x-ai/grok-3-mini-beta::3_11_2::2        2             3  \n",
       "0  x-ai/grok-3-mini-beta::3_11_2::2        3             3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the root directory containing the subdirectories and JSON files\n",
    "root_dir = 'responses'\n",
    "\n",
    "# Prepare a list to collect all the JSON data\n",
    "data_list = []\n",
    "\n",
    "# Walk through the directory tree\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            json_path = os.path.join(subdir, file)\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    data_list.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON: {json_path}\")\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df.head(6).sort_values(by=[\"run_id\", \"attempt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "713d220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22411879999999998)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = df['cost'].sum()\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy code to make up pass@k values; delete this later\n",
    "new_success = []\n",
    "\n",
    "for run_id, group in df.groupby('run_id'):\n",
    "    attempts = sorted(group['attempt'].unique())\n",
    "\n",
    "    # Assume max_attempt is the max of current group\n",
    "    max_attempt = max(attempts)\n",
    "    last_attempt = attempts[-1]\n",
    "\n",
    "    a1 = np.random.rand() < 0.3\n",
    "    a2 = a1 or (np.random.rand() < 0.3)\n",
    "    success_map = {\n",
    "        1: a1,\n",
    "        2: a2,\n",
    "        last_attempt: True  # Always succeeds on last attempt\n",
    "    }\n",
    "\n",
    "    # Fill in intermediate attempts if needed\n",
    "    for attempt in attempts:\n",
    "        if attempt not in success_map:\n",
    "            # If more than 3 attempts: fallback logic, extend success from previous\n",
    "            success_map[attempt] = success_map.get(attempt - 1, False)\n",
    "\n",
    "    for attempt in attempts:\n",
    "        new_success.append(success_map[attempt])\n",
    "\n",
    "# Overwrite df['success']\n",
    "df['success'] = new_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c304038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per model}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "model & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "openai/o4-mini & 18.180000 \\\\\n",
      "x-ai/grok-3-mini-beta & 16.670000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per model\n",
    "summary = df.groupby('model')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per model\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff873336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per exercise}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "exercise & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "11_not_closed & 0.000000 \\\\\n",
      "3_11_2 & 36.360000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per exercise (check if this code is correct)\n",
    "summary = df.groupby('exercise')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per exercise\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa34b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>exercise</th>\n",
       "      <th>11_not_closed</th>\n",
       "      <th>3_11_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>openai/o4-mini</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-ai/grok-3-mini-beta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "exercise               11_not_closed  3_11_2\n",
       "model                                       \n",
       "openai/o4-mini                   0.0   40.00\n",
       "x-ai/grok-3-mini-beta            0.0   33.33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid of success rates per model and per exercise (requires multiple runs of all models)\n",
    "grid = df.pivot_table(index='model', columns='exercise', values='success', aggfunc='mean') * 100\n",
    "grid = grid.round(2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3385308",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: thinking_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m output_tokens_avg.rename(columns={\u001b[33m'\u001b[39m\u001b[33moutput_tokens\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mAvg Output Tokens\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Average thinking token counts per model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m thinking_tokens_avg = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mthinking_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.mean().reset_index()\n\u001b[32m      7\u001b[39m thinking_tokens_avg.rename(columns={\u001b[33m'\u001b[39m\u001b[33mthinking_tokens\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mAvg Thinking Tokens\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Get the thinking_mode per model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BEP/bep-openai-testing/venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951\u001b[39m, in \u001b[36mDataFrameGroupBy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m1\u001b[39m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[32m   1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1950\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BEP/bep-openai-testing/venv/lib/python3.12/site-packages/pandas/core/base.py:244\u001b[39m, in \u001b[36mSelectionMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    245\u001b[39m     ndim = \u001b[38;5;28mself\u001b[39m.obj[key].ndim\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gotitem(key, ndim=ndim)\n",
      "\u001b[31mKeyError\u001b[39m: 'Column not found: thinking_tokens'"
     ]
    }
   ],
   "source": [
    "# Average output token counts per model\n",
    "output_tokens_avg = df.groupby('model')['output_tokens'].mean().reset_index()\n",
    "output_tokens_avg.rename(columns={'output_tokens': 'Avg Output Tokens'}, inplace=True)\n",
    "\n",
    "# Average thinking token counts per model\n",
    "thinking_tokens_avg = df.groupby('model')['thinking_tokens'].mean().reset_index()\n",
    "thinking_tokens_avg.rename(columns={'thinking_tokens': 'Avg Thinking Tokens'}, inplace=True)\n",
    "\n",
    "# Get the thinking_mode per model\n",
    "thinking_mode_per_model = df[['model', 'thinking_mode']].drop_duplicates()\n",
    "\n",
    "# Merge into the result\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_mode_per_model, on='model')\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_tokens_avg, on='model')\n",
    "\n",
    "output_tokens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9305b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Cost ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.019011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Avg Cost ($)\n",
       "0         openai/o4-mini      0.019011\n",
       "1  x-ai/grok-3-mini-beta      0.001250"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cost per model\n",
    "cost_avg = df.groupby('model')['cost'].mean().reset_index()\n",
    "cost_avg.rename(columns={'cost': 'Avg Cost ($)'}, inplace=True)\n",
    "cost_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d371e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Tutorial Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>8665</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Tutorial Length  Success Rate (%)\n",
       "0         openai/o4-mini             8665             18.18\n",
       "1  x-ai/grok-3-mini-beta             8665             16.67"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of tutorial verbosity\n",
    "df['tutorial_len'] = df['tutorial'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "tutorial_success = df.groupby(['model', 'tutorial_len'])['success'].mean().reset_index()\n",
    "tutorial_success['success'] = (tutorial_success['success'] * 100).round(2)\n",
    "tutorial_success.rename(columns={'success': 'Success Rate (%)', 'tutorial_len': 'Tutorial Length'}, inplace=True)\n",
    "\n",
    "tutorial_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15669877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Prompt Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>1294</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Prompt Length  Success Rate (%)\n",
       "0         openai/o4-mini           1294             18.18\n",
       "1  x-ai/grok-3-mini-beta           1294             16.67"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of prompt verbosity\n",
    "df['prompt_len'] = df['prompt'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "prompt_success = df.groupby(['model', 'prompt_len'])['success'].mean().reset_index()\n",
    "prompt_success['success'] = (prompt_success['success'] * 100).round(2)\n",
    "prompt_success.rename(columns={'success': 'Success Rate (%)', 'prompt_len': 'Prompt Length'}, inplace=True)\n",
    "\n",
    "prompt_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3f29623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [errors]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['exercise'] == '6_8_1']\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_filtered['errors'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00323cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_with_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [line_with_error]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['line_with_error'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72e35710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Pass@1 (%)</th>\n",
       "      <th>Pass@2 (%)</th>\n",
       "      <th>Pass@3 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Pass@1 (%)  Pass@2 (%)  Pass@3 (%)\n",
       "0         openai/o4-mini        25.0        50.0        50.0\n",
       "1  x-ai/grok-3-mini-beta        50.0        50.0        50.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by run_id to get per-run summary\n",
    "run_grouped = df.groupby('run_id').agg({\n",
    "    'model': 'first',\n",
    "    'success': list,\n",
    "    'attempt': 'max',\n",
    "    'max_attempts': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Expand success list into per-k success map\n",
    "max_k = df['max_attempts'].max()\n",
    "\n",
    "for k in range(1, max_k + 1):\n",
    "    def pass_at_k(row):\n",
    "        successes = row['success']\n",
    "        used_attempts = row['attempt']\n",
    "        # Success in any of the first k attempts\n",
    "        success_in_k = any(successes[:k])\n",
    "        # Or the model didn't even use k attempts\n",
    "        not_used_k = used_attempts < k\n",
    "        return success_in_k or not_used_k\n",
    "\n",
    "    run_grouped[f'pass@{k}'] = run_grouped.apply(pass_at_k, axis=1)\n",
    "\n",
    "# Now compute per-model mean for each pass@k\n",
    "passk_cols = [f'pass@{k}' for k in range(1, max_k + 1)]\n",
    "passk_summary = run_grouped.groupby('model')[passk_cols].mean().reset_index()\n",
    "\n",
    "# Convert to percentage\n",
    "for col in passk_cols:\n",
    "    passk_summary[col] = (passk_summary[col] * 100).round(2)\n",
    "\n",
    "# Rename columns for display\n",
    "passk_summary.rename(columns={col: f'Pass@{col[-1]} (%)' for col in passk_cols}, inplace=True)\n",
    "\n",
    "passk_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# thinking vs no thinking models (all)\n",
    "# thinking vs no thinking on models that support both (fair)\n",
    "# definition expanding comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
