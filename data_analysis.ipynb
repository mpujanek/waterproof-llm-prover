{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ba4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e756930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>exercise</th>\n",
       "      <th>prompt</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>exercise_content</th>\n",
       "      <th>output</th>\n",
       "      <th>token_count</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>cost</th>\n",
       "      <th>thinking_mode</th>\n",
       "      <th>errors</th>\n",
       "      <th>line_with_error</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>10_7_intermediate</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Section exercise_10_7_3.\\n\\nVariable (X : Metr...</td>\n",
       "      <td>Proof.\\nWe need to show that (∀ k ∈ ℕ, n(k) &lt; ...</td>\n",
       "      <td>7114</td>\n",
       "      <td>4304</td>\n",
       "      <td>2810</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E10_7_intermediate_7dek2n62.v\", lin...</td>\n",
       "      <td>By the definition of n, n(k) = 2 * k and n(k +...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>10_7_intermediate</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Section exercise_10_7_3.\\n\\nVariable (X : Metr...</td>\n",
       "      <td>Proof.\\nTake k ∈ ℕ.\\nWe need to show that (n(k...</td>\n",
       "      <td>7374</td>\n",
       "      <td>5337</td>\n",
       "      <td>2037</td>\n",
       "      <td>0.046566</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>10_7_intermediate</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Section exercise_10_7_3.\\n\\nVariable (X : Metr...</td>\n",
       "      <td>Take k ∈ ℕ.\\nWe need to show that (n(k) &lt; n(k ...</td>\n",
       "      <td>3841</td>\n",
       "      <td>3718</td>\n",
       "      <td>123</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>10_7_intermediate</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Section exercise_10_7_3.\\n\\nVariable (X : Metr...</td>\n",
       "      <td>Proof.\\nTake k ∈ ℕ.\\nWe need to show that (2 *...</td>\n",
       "      <td>4903</td>\n",
       "      <td>2609</td>\n",
       "      <td>2294</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>10_7_intermediate</td>\n",
       "      <td>You are asked to write a proof in the syntax o...</td>\n",
       "      <td># Waterproof Tutorial\\n\\n## 1. We conclude tha...</td>\n",
       "      <td>Section exercise_10_7_3.\\n\\nVariable (X : Metr...</td>\n",
       "      <td>Proof.\\nTake k ∈ ℕ.\\nWe need to show that (n(k...</td>\n",
       "      <td>8451</td>\n",
       "      <td>3727</td>\n",
       "      <td>4724</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>True</td>\n",
       "      <td>File \"/tmp/E10_7_intermediate_ry_2bot8.v\", lin...</td>\n",
       "      <td>We conclude that (2 * k &lt; 2 * (k + 1)).</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model           exercise  \\\n",
       "0                        openai/o1-mini  10_7_intermediate   \n",
       "1  anthropic/claude-3.7-sonnet:thinking  10_7_intermediate   \n",
       "2           meta-llama/llama-4-maverick  10_7_intermediate   \n",
       "3                     qwen/qwq-32b:free  10_7_intermediate   \n",
       "4                  qwen/qwen3-235b-a22b  10_7_intermediate   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  You are asked to write a proof in the syntax o...   \n",
       "1  You are asked to write a proof in the syntax o...   \n",
       "2  You are asked to write a proof in the syntax o...   \n",
       "3  You are asked to write a proof in the syntax o...   \n",
       "4  You are asked to write a proof in the syntax o...   \n",
       "\n",
       "                                            tutorial  \\\n",
       "0  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "1  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "2  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "3  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "4  # Waterproof Tutorial\\n\\n## 1. We conclude tha...   \n",
       "\n",
       "                                    exercise_content  \\\n",
       "0  Section exercise_10_7_3.\\n\\nVariable (X : Metr...   \n",
       "1  Section exercise_10_7_3.\\n\\nVariable (X : Metr...   \n",
       "2  Section exercise_10_7_3.\\n\\nVariable (X : Metr...   \n",
       "3  Section exercise_10_7_3.\\n\\nVariable (X : Metr...   \n",
       "4  Section exercise_10_7_3.\\n\\nVariable (X : Metr...   \n",
       "\n",
       "                                              output  token_count  \\\n",
       "0  Proof.\\nWe need to show that (∀ k ∈ ℕ, n(k) < ...         7114   \n",
       "1  Proof.\\nTake k ∈ ℕ.\\nWe need to show that (n(k...         7374   \n",
       "2  Take k ∈ ℕ.\\nWe need to show that (n(k) < n(k ...         3841   \n",
       "3  Proof.\\nTake k ∈ ℕ.\\nWe need to show that (2 *...         4903   \n",
       "4  Proof.\\nTake k ∈ ℕ.\\nWe need to show that (n(k...         8451   \n",
       "\n",
       "   input_tokens  output_tokens      cost  thinking_mode  \\\n",
       "0          4304           2810  0.017098           True   \n",
       "1          5337           2037  0.046566           True   \n",
       "2          3718            123  0.000669          False   \n",
       "3          2609           2294  0.000850           True   \n",
       "4          3727           4724  0.003356           True   \n",
       "\n",
       "                                              errors  \\\n",
       "0  File \"/tmp/E10_7_intermediate_7dek2n62.v\", lin...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  File \"/tmp/E10_7_intermediate_ry_2bot8.v\", lin...   \n",
       "\n",
       "                                     line_with_error  success  \n",
       "0  By the definition of n, n(k) = 2 * k and n(k +...    False  \n",
       "1                                               None     True  \n",
       "2                                               None     True  \n",
       "3                                               None     True  \n",
       "4            We conclude that (2 * k < 2 * (k + 1)).    False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the root directory containing the subdirectories and JSON files\n",
    "root_dir = 'responses'\n",
    "\n",
    "# Prepare a list to collect all the JSON data\n",
    "data_list = []\n",
    "\n",
    "# Walk through the directory tree\n",
    "for subdir, _, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            json_path = os.path.join(subdir, file)\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    data_list.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON: {json_path}\")\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "713d220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.14488195)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost = df['cost'].sum()\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c304038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per model}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "model & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "anthropic/claude-3.7-sonnet & 100.000000 \\\\\n",
      "anthropic/claude-3.7-sonnet:thinking & 100.000000 \\\\\n",
      "anthropic/claude-sonnet-4 & 0.000000 \\\\\n",
      "deepseek/deepseek-chat-v3-0324:free & 0.000000 \\\\\n",
      "deepseek/deepseek-prover-v2:free & 0.000000 \\\\\n",
      "deepseek/deepseek-r1:free & 0.000000 \\\\\n",
      "google/gemini-2.5-flash-preview-05-20 & 0.000000 \\\\\n",
      "google/gemini-2.5-flash-preview-05-20:thinking & 0.000000 \\\\\n",
      "meta-llama/llama-3.3-70b-instruct & 0.000000 \\\\\n",
      "meta-llama/llama-4-maverick & 100.000000 \\\\\n",
      "nousresearch/hermes-3-llama-3.1-405b & 0.000000 \\\\\n",
      "nousresearch/hermes-3-llama-3.1-70b & 0.000000 \\\\\n",
      "openai/o1-mini & 0.000000 \\\\\n",
      "openai/o3-mini & 0.000000 \\\\\n",
      "openai/o4-mini & 100.000000 \\\\\n",
      "qwen/qwen-2.5-72b-instruct & 0.000000 \\\\\n",
      "qwen/qwen3-235b-a22b & 0.000000 \\\\\n",
      "qwen/qwq-32b:free & 100.000000 \\\\\n",
      "x-ai/grok-3-mini-beta & 0.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per model\n",
    "summary = df.groupby('model')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per model\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff873336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Success rate per exercise}\n",
      "\\label{tab:success_rate}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "exercise & Success Rate (%) \\\\\n",
      "\\midrule\n",
      "10_7_intermediate & 26.320000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total success rate per exercise (check if this code is correct)\n",
    "summary = df.groupby('exercise')['success'].mean().reset_index()\n",
    "summary['success'] = (summary['success'] * 100).round(2)  # Convert to percentage\n",
    "summary.rename(columns={'success': 'Success Rate (%)'}, inplace=True)\n",
    "\n",
    "# Export to LaTeX\n",
    "latex_table = summary.to_latex(index=False, column_format=\"ll\", caption=\"Success rate per exercise\", label=\"tab:success_rate\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baa34b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>exercise</th>\n",
       "      <th>10_7_intermediate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-3.7-sonnet</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-3.7-sonnet:thinking</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-sonnet-4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-chat-v3-0324:free</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-prover-v2:free</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek/deepseek-r1:free</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-2.5-flash-preview-05-20:thinking</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-3.3-70b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/llama-4-maverick</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/hermes-3-llama-3.1-405b</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nousresearch/hermes-3-llama-3.1-70b</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o1-mini</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o3-mini</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/o4-mini</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen-2.5-72b-instruct</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwen3-235b-a22b</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen/qwq-32b:free</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-ai/grok-3-mini-beta</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "exercise                                        10_7_intermediate\n",
       "model                                                            \n",
       "anthropic/claude-3.7-sonnet                                 100.0\n",
       "anthropic/claude-3.7-sonnet:thinking                        100.0\n",
       "anthropic/claude-sonnet-4                                     0.0\n",
       "deepseek/deepseek-chat-v3-0324:free                           0.0\n",
       "deepseek/deepseek-prover-v2:free                              0.0\n",
       "deepseek/deepseek-r1:free                                     0.0\n",
       "google/gemini-2.5-flash-preview-05-20                         0.0\n",
       "google/gemini-2.5-flash-preview-05-20:thinking                0.0\n",
       "meta-llama/llama-3.3-70b-instruct                             0.0\n",
       "meta-llama/llama-4-maverick                                 100.0\n",
       "nousresearch/hermes-3-llama-3.1-405b                          0.0\n",
       "nousresearch/hermes-3-llama-3.1-70b                           0.0\n",
       "openai/o1-mini                                                0.0\n",
       "openai/o3-mini                                                0.0\n",
       "openai/o4-mini                                              100.0\n",
       "qwen/qwen-2.5-72b-instruct                                    0.0\n",
       "qwen/qwen3-235b-a22b                                          0.0\n",
       "qwen/qwq-32b:free                                           100.0\n",
       "x-ai/grok-3-mini-beta                                         0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid of success rates per model and per exercise (requires multiple runs of all models)\n",
    "grid = df.pivot_table(index='model', columns='exercise', values='success', aggfunc='mean') * 100\n",
    "grid = grid.round(2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3385308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Output Tokens</th>\n",
       "      <th>thinking_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>181.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>109.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>207.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>159.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>3461.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>118.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>485.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>93.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>123.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>427.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>392.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>4724.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Avg Output Tokens  \\\n",
       "0                      anthropic/claude-3.7-sonnet              181.0   \n",
       "1             anthropic/claude-3.7-sonnet:thinking             2037.0   \n",
       "2                        anthropic/claude-sonnet-4              109.0   \n",
       "3              deepseek/deepseek-chat-v3-0324:free              207.0   \n",
       "4                 deepseek/deepseek-prover-v2:free              159.0   \n",
       "5                        deepseek/deepseek-r1:free             3461.0   \n",
       "6            google/gemini-2.5-flash-preview-05-20              118.0   \n",
       "7   google/gemini-2.5-flash-preview-05-20:thinking              485.0   \n",
       "8                meta-llama/llama-3.3-70b-instruct               93.0   \n",
       "9                      meta-llama/llama-4-maverick              123.0   \n",
       "10            nousresearch/hermes-3-llama-3.1-405b              427.0   \n",
       "11             nousresearch/hermes-3-llama-3.1-70b              392.0   \n",
       "12                                  openai/o1-mini             2810.0   \n",
       "13                                  openai/o3-mini             1053.0   \n",
       "14                                  openai/o4-mini             1584.0   \n",
       "15                      qwen/qwen-2.5-72b-instruct               79.0   \n",
       "16                            qwen/qwen3-235b-a22b             4724.0   \n",
       "17                               qwen/qwq-32b:free             2294.0   \n",
       "18                           x-ai/grok-3-mini-beta               42.0   \n",
       "\n",
       "    thinking_mode  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "5            True  \n",
       "6           False  \n",
       "7            True  \n",
       "8           False  \n",
       "9           False  \n",
       "10          False  \n",
       "11          False  \n",
       "12           True  \n",
       "13           True  \n",
       "14           True  \n",
       "15          False  \n",
       "16           True  \n",
       "17           True  \n",
       "18           True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average output token counts per model\n",
    "output_tokens_avg = df.groupby('model')['output_tokens'].mean().reset_index()\n",
    "output_tokens_avg.rename(columns={'output_tokens': 'Avg Output Tokens'}, inplace=True)\n",
    "\n",
    "# Get the thinking_mode per model\n",
    "thinking_mode_per_model = df[['model', 'thinking_mode']].drop_duplicates()\n",
    "\n",
    "# Merge into the result\n",
    "output_tokens_avg = output_tokens_avg.merge(thinking_mode_per_model, on='model')\n",
    "\n",
    "output_tokens_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9305b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Avg Cost ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>0.046566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>0.017562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>0.009424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>0.017098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>0.008910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.011246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Avg Cost ($)\n",
       "0                      anthropic/claude-3.7-sonnet      0.018642\n",
       "1             anthropic/claude-3.7-sonnet:thinking      0.046566\n",
       "2                        anthropic/claude-sonnet-4      0.017562\n",
       "3              deepseek/deepseek-chat-v3-0324:free      0.001309\n",
       "4                 deepseek/deepseek-prover-v2:free      0.002225\n",
       "5                        deepseek/deepseek-r1:free      0.009424\n",
       "6            google/gemini-2.5-flash-preview-05-20      0.000698\n",
       "7   google/gemini-2.5-flash-preview-05-20:thinking      0.000918\n",
       "8                meta-llama/llama-3.3-70b-instruct      0.000283\n",
       "9                      meta-llama/llama-4-maverick      0.000669\n",
       "10            nousresearch/hermes-3-llama-3.1-405b      0.002939\n",
       "11             nousresearch/hermes-3-llama-3.1-70b      0.000563\n",
       "12                                  openai/o1-mini      0.017098\n",
       "13                                  openai/o3-mini      0.008910\n",
       "14                                  openai/o4-mini      0.011246\n",
       "15                      qwen/qwen-2.5-72b-instruct      0.000478\n",
       "16                            qwen/qwen3-235b-a22b      0.003356\n",
       "17                               qwen/qwq-32b:free      0.000850\n",
       "18                           x-ai/grok-3-mini-beta      0.001147"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cost per model\n",
    "cost_avg = df.groupby('model')['cost'].mean().reset_index()\n",
    "cost_avg.rename(columns={'cost': 'Avg Cost ($)'}, inplace=True)\n",
    "cost_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d371e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Tutorial Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>8665</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>8665</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>8665</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>8665</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>8665</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Tutorial Length  \\\n",
       "0                      anthropic/claude-3.7-sonnet             8665   \n",
       "1             anthropic/claude-3.7-sonnet:thinking             8665   \n",
       "2                        anthropic/claude-sonnet-4             8665   \n",
       "3              deepseek/deepseek-chat-v3-0324:free             8665   \n",
       "4                 deepseek/deepseek-prover-v2:free             8665   \n",
       "5                        deepseek/deepseek-r1:free             8665   \n",
       "6            google/gemini-2.5-flash-preview-05-20             8665   \n",
       "7   google/gemini-2.5-flash-preview-05-20:thinking             8665   \n",
       "8                meta-llama/llama-3.3-70b-instruct             8665   \n",
       "9                      meta-llama/llama-4-maverick             8665   \n",
       "10            nousresearch/hermes-3-llama-3.1-405b             8665   \n",
       "11             nousresearch/hermes-3-llama-3.1-70b             8665   \n",
       "12                                  openai/o1-mini             8665   \n",
       "13                                  openai/o3-mini             8665   \n",
       "14                                  openai/o4-mini             8665   \n",
       "15                      qwen/qwen-2.5-72b-instruct             8665   \n",
       "16                            qwen/qwen3-235b-a22b             8665   \n",
       "17                               qwen/qwq-32b:free             8665   \n",
       "18                           x-ai/grok-3-mini-beta             8665   \n",
       "\n",
       "    Success Rate (%)  \n",
       "0              100.0  \n",
       "1              100.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "6                0.0  \n",
       "7                0.0  \n",
       "8                0.0  \n",
       "9              100.0  \n",
       "10               0.0  \n",
       "11               0.0  \n",
       "12               0.0  \n",
       "13               0.0  \n",
       "14             100.0  \n",
       "15               0.0  \n",
       "16               0.0  \n",
       "17             100.0  \n",
       "18               0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of tutorial verbosity\n",
    "df['tutorial_len'] = df['tutorial'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "tutorial_success = df.groupby(['model', 'tutorial_len'])['success'].mean().reset_index()\n",
    "tutorial_success['success'] = (tutorial_success['success'] * 100).round(2)\n",
    "tutorial_success.rename(columns={'success': 'Success Rate (%)', 'tutorial_len': 'Tutorial Length'}, inplace=True)\n",
    "\n",
    "tutorial_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15669877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Prompt Length</th>\n",
       "      <th>Success Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic/claude-3.7-sonnet</td>\n",
       "      <td>1294</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>1294</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anthropic/claude-sonnet-4</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3-0324:free</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek/deepseek-prover-v2:free</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek/deepseek-r1:free</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/gemini-2.5-flash-preview-05-20:thinking</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/llama-3.3-70b-instruct</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta-llama/llama-4-maverick</td>\n",
       "      <td>1294</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-405b</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nousresearch/hermes-3-llama-3.1-70b</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai/o1-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openai/o3-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>1294</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen/qwen-2.5-72b-instruct</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen/qwen3-235b-a22b</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qwen/qwq-32b:free</td>\n",
       "      <td>1294</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x-ai/grok-3-mini-beta</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model  Prompt Length  \\\n",
       "0                      anthropic/claude-3.7-sonnet           1294   \n",
       "1             anthropic/claude-3.7-sonnet:thinking           1294   \n",
       "2                        anthropic/claude-sonnet-4           1294   \n",
       "3              deepseek/deepseek-chat-v3-0324:free           1294   \n",
       "4                 deepseek/deepseek-prover-v2:free           1294   \n",
       "5                        deepseek/deepseek-r1:free           1294   \n",
       "6            google/gemini-2.5-flash-preview-05-20           1294   \n",
       "7   google/gemini-2.5-flash-preview-05-20:thinking           1294   \n",
       "8                meta-llama/llama-3.3-70b-instruct           1294   \n",
       "9                      meta-llama/llama-4-maverick           1294   \n",
       "10            nousresearch/hermes-3-llama-3.1-405b           1294   \n",
       "11             nousresearch/hermes-3-llama-3.1-70b           1294   \n",
       "12                                  openai/o1-mini           1294   \n",
       "13                                  openai/o3-mini           1294   \n",
       "14                                  openai/o4-mini           1294   \n",
       "15                      qwen/qwen-2.5-72b-instruct           1294   \n",
       "16                            qwen/qwen3-235b-a22b           1294   \n",
       "17                               qwen/qwq-32b:free           1294   \n",
       "18                           x-ai/grok-3-mini-beta           1294   \n",
       "\n",
       "    Success Rate (%)  \n",
       "0              100.0  \n",
       "1              100.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "6                0.0  \n",
       "7                0.0  \n",
       "8                0.0  \n",
       "9              100.0  \n",
       "10               0.0  \n",
       "11               0.0  \n",
       "12               0.0  \n",
       "13               0.0  \n",
       "14             100.0  \n",
       "15               0.0  \n",
       "16               0.0  \n",
       "17             100.0  \n",
       "18               0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success rate per model compared across a few levels of prompt verbosity\n",
    "df['prompt_len'] = df['prompt'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "prompt_success = df.groupby(['model', 'prompt_len'])['success'].mean().reset_index()\n",
    "prompt_success['success'] = (prompt_success['success'] * 100).round(2)\n",
    "prompt_success.rename(columns={'success': 'Success Rate (%)', 'prompt_len': 'Prompt Length'}, inplace=True)\n",
    "\n",
    "prompt_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e35710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass@k success rate per model; can mention if a model consistently did not use all k attempts\n",
    "df['pass@k'] = df['success'] | (df['used_attempts'] < df['max_attempts'])\n",
    "passk_summary = df.groupby('model')['pass@k'].mean().reset_index()\n",
    "passk_summary['pass@k'] = (passk_summary['pass@k'] * 100).round(2)\n",
    "passk_summary.rename(columns={'pass@k': 'Pass@k Rate (%)'}, inplace=True)\n",
    "passk_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# thinking vs no thinking models (all)\n",
    "# thinking vs no thinking on models that support both (fair)\n",
    "# definition expanding comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
